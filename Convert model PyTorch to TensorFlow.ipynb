{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "K = keras.backend\n",
    "from model import BiSeNet\n",
    "\n",
    "from resnet import Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_pytorch_model(save_path=os.path.join(\"res/cp\", \"79999_iter.pth\")):\n",
    "    n_classes = 19\n",
    "    \n",
    "    net = BiSeNet(n_classes=n_classes)\n",
    "#     net.cuda()\n",
    "    \n",
    "    net.load_state_dict(torch.load(save_path))\n",
    "#     net.eval()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pytorch = restore_pytorch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiSeNet(\n",
       "  (cp): ContextPath(\n",
       "    (resnet): Resnet18(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (arm16): AttentionRefinementModule(\n",
       "      (conv): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sigmoid_atten): Sigmoid()\n",
       "    )\n",
       "    (arm32): AttentionRefinementModule(\n",
       "      (conv): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sigmoid_atten): Sigmoid()\n",
       "    )\n",
       "    (conv_head32): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_head16): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_avg): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ffm): FeatureFusionModule(\n",
       "    (convblk): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (conv_out): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_out16): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_out32): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_url = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return keras.layers.Conv2D(\n",
    "#         in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3, \n",
    "        strides=stride,\n",
    "        padding=\"same\", \n",
    "        use_bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "class BasicBlock(keras.layers.Layer):\n",
    "    def __init__(self, in_chan, out_chan, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = conv3x3(in_chan, out_chan, stride)\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = conv3x3(out_chan, out_chan)\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "        self.relu = keras.activations.relu\n",
    "        self.downsample = None\n",
    "        if in_chan != out_chan or stride != 1:\n",
    "            self.downsample = keras.models.Sequential()\n",
    "            self.downsample.add(\n",
    "                keras.layers.Conv2D(\n",
    "#                     in_chan, \n",
    "                    out_chan,\n",
    "                    kernel_size=1, \n",
    "                    strides=stride, \n",
    "                    use_bias=False\n",
    "                )\n",
    "            )\n",
    "            self.downsample.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = self.conv1(x)\n",
    "        residual = self.relu(self.bn1(residual))\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "\n",
    "        shortcut = x\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "\n",
    "        out = shortcut + residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "    # TODO\n",
    "    def load_weigths_pytorch(self, state_dict):\n",
    "        layers = [\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.conv2,\n",
    "            self.bn2,\n",
    "        ]\n",
    "        pth_layer_names = [\n",
    "            \"conv1\",\n",
    "            \"bn1\",\n",
    "            \"conv2\",\n",
    "            \"bn2\",\n",
    "        ]\n",
    "        \n",
    "        for layer, pth_layer_name in zip(layers, pth_layer_names):\n",
    "            layer_state_dict = filter_dict_by_name(pth_layer_name, state_dict)\n",
    "            layer_state_dict = strip_dict_key_prefix(layer_state_dict)\n",
    "            \n",
    "            if isinstance(layer, keras.layers.Conv2D):\n",
    "                weights_conversion_fn = conv2d_weights_pth2tf\n",
    "            elif isinstance(layer, keras.layers.BatchNormalization):\n",
    "                weights_conversion_fn = bn_weights_pth2tf\n",
    "                \n",
    "#             print(layer_state_dict)\n",
    "            layer.set_weights(weights_conversion_fn(layer_state_dict))\n",
    "    \n",
    "        if self.downsample is not None:\n",
    "            for idx, layer in enumerate(self.downsample):\n",
    "                print(f\"idx: {idx}, layer type: {type(layer)}\")\n",
    "\n",
    "                layer_state_dict = filter_dict_by_name(f\"downsample.{idx}\", state_dict)\n",
    "                layer_state_dict = strip_dict_key_prefix(layer_state_dict, cut=2)\n",
    "                \n",
    "                if isinstance(layer, keras.layers.Conv2D):\n",
    "                    weights_conversion_fn = conv2d_weights_pth2tf\n",
    "                elif isinstance(layer, keras.layers.BatchNormalization):\n",
    "                    weights_conversion_fn = bn_weights_pth2tf\n",
    "                    \n",
    "                layer.set_weights(weights_conversion_fn(layer_state_dict))\n",
    "\n",
    "    \n",
    "        print(\"Done loading BasicBlock weights!\")\n",
    "\n",
    "\n",
    "def create_layer_basic(in_chan, out_chan, bnum, stride=1):\n",
    "#     layers = [BasicBlock(in_chan, out_chan, stride=stride)]\n",
    "#     for i in range(bnum-1):\n",
    "#         layers.append(BasicBlock(out_chan, out_chan, stride=1))\n",
    "#     return nn.Sequential(*layers)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(BasicBlock(in_chan, out_chan, stride=stride))\n",
    "    for i in range(bnum - 1):\n",
    "        model.add(BasicBlock(out_chan, out_chan, stride=1))\n",
    "    return model\n",
    "\n",
    "\n",
    "class tfResnet18(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(tfResnet18, self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(\n",
    "#             3, \n",
    "            64, \n",
    "            kernel_size=7, \n",
    "            strides=2, \n",
    "            padding=\"same\",\n",
    "            use_bias=False\n",
    "        )\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.maxpool = keras.layers.MaxPool2D(3, strides=2, padding=\"same\")\n",
    "        self.layer1 = create_layer_basic(64, 64, bnum=2, stride=1)\n",
    "        self.layer2 = create_layer_basic(64, 128, bnum=2, stride=2)\n",
    "        self.layer3 = create_layer_basic(128, 256, bnum=2, stride=2)\n",
    "        self.layer4 = create_layer_basic(256, 512, bnum=2, stride=2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = K.relu(self.bn1(x))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        feat8 = self.layer2(x) # 1/8\n",
    "        feat16 = self.layer3(feat8) # 1/16\n",
    "        feat32 = self.layer4(feat16) # 1/32\n",
    "        return feat8, feat16, feat32\n",
    "    \n",
    "    def load_weigths_pytorch(self, weights_path):\n",
    "        model_state_dict = torch.load(weights_path)\n",
    "        \n",
    "        layers = [\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "        ]\n",
    "        pth_layer_names = [\n",
    "            \"conv1\",\n",
    "            \"bn1\",\n",
    "        ]\n",
    "        \n",
    "        for layer, pth_layer_name in zip(layers, pth_layer_names):\n",
    "            layer_state_dict = filter_dict_by_name(pth_layer_name, model_state_dict)\n",
    "            layer_state_dict = strip_dict_key_prefix(layer_state_dict)\n",
    "            \n",
    "            if isinstance(layer, keras.layers.Conv2D):\n",
    "                weights_conversion_fn = conv2d_weights_pth2tf\n",
    "            elif isinstance(layer, keras.layers.BatchNormalization):\n",
    "                weights_conversion_fn = bn_weights_pth2tf\n",
    "                \n",
    "#             print(layer_state_dict)\n",
    "            layer.set_weights(weights_conversion_fn(layer_state_dict))\n",
    "            \n",
    "            \n",
    "    \n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        for idx, layer in enumerate(self.layer1.layers):\n",
    "            print(f\"idx: {idx}, layer type: {type(layer)}\")\n",
    "            print(isinstance(layer, BasicBlock))\n",
    "            \n",
    "            layer_state_dict = filter_dict_by_name(f\"layer1.{idx}\", model_state_dict)\n",
    "            layer_state_dict = strip_dict_key_prefix(layer_state_dict, cut=2)\n",
    "            print(layer_state_dict)\n",
    "            layer.load_weigths_pytorch(layer_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(param_names):\n",
    "    layers = []\n",
    "    \n",
    "    for name in param_names:\n",
    "        lname = \".\".join(name.split(\".\")[:-1])\n",
    "        \n",
    "        if lname not in layers:\n",
    "            layers.append(lname)\n",
    "        \n",
    "    return layers\n",
    "\n",
    "\n",
    "def filter_dict_by_name(name, model_state_dict):\n",
    "    return dict(filter(lambda t: t[0].startswith(name),  model_state_dict.items()))\n",
    "\n",
    "\n",
    "def conv2d_weights_pth2tf(params_dict):\n",
    "#     weights = []\n",
    "    \n",
    "#     for _, t in params_dict.items():\n",
    "#         t = t.detach().numpy()\n",
    "        \n",
    "#         if t.ndim == 4:    \n",
    "#             t = np.transpose(t, [2, 3, 1, 0])\n",
    "            \n",
    "#         weights.append(t)\n",
    "    \n",
    "#     return weights\n",
    "\n",
    "    weights = []\n",
    "    \n",
    "    params_dict = strip_dict_key_prefix(params_dict, -1)\n",
    "    \n",
    "    # gamma, beta, moving_mean, moving_variance\n",
    "    for key in [\"weight\", \"bias\"]:\n",
    "        if key not in params_dict:\n",
    "            continue\n",
    "            \n",
    "        if key == \"weight\":\n",
    "            weights.append(np.transpose(params_dict[key].detach().numpy(), [2, 3, 1, 0]))\n",
    "        else:\n",
    "            weights.append(params_dict[key].detach().numpy())\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def strip_dict_key_prefix(params_dict, cut=-2):\n",
    "    return {f\"{'.'.join(k.split('.')[cut:])}\": v for k, v in params_dict.items()}\n",
    "\n",
    "\n",
    "def bn_weights_pth2tf(params_dict):\n",
    "    weights = []\n",
    "    \n",
    "    params_dict = strip_dict_key_prefix(params_dict, -1)\n",
    "    \n",
    "    # gamma, beta, moving_mean, moving_variance\n",
    "    for key in [\"weight\", \"bias\", \"running_mean\", \"running_var\"]:\n",
    "        weights.append(params_dict[key].detach().numpy())\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 28, 28, 128)\n",
      "(16, 14, 14, 256)\n",
      "(16, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "net_tf = tfResnet18()\n",
    "x = tf.random.normal((16, 224, 224, 3))\n",
    "out = net_tf(x)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)\n",
    "print(out[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "idx: 0, layer type: <class '__main__.BasicBlock'>\n",
      "True\n",
      "{'conv1.weight': Parameter containing:\n",
      "tensor([[[[ 5.7593e-02, -9.5114e-02, -2.0272e-02],\n",
      "          [-7.4556e-02, -7.9931e-01, -2.1284e-01],\n",
      "          [ 6.5571e-02, -9.6534e-02, -1.2111e-02]],\n",
      "\n",
      "         [[-6.9944e-03,  1.4266e-02,  5.5824e-04],\n",
      "          [ 4.1238e-02, -1.6125e-01, -2.3208e-02],\n",
      "          [ 3.2887e-03,  7.1779e-03,  7.1686e-02]],\n",
      "\n",
      "         [[-2.3627e-09, -3.9270e-08, -3.2971e-08],\n",
      "          [ 2.1737e-08,  8.3299e-09,  1.2543e-08],\n",
      "          [ 1.1382e-08,  8.8096e-09,  1.5506e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6921e-02,  1.8294e-02, -2.9358e-02],\n",
      "          [-9.8615e-02, -4.3645e-02, -5.2717e-02],\n",
      "          [-7.9635e-02,  2.9396e-02,  4.1479e-03]],\n",
      "\n",
      "         [[ 1.6948e-02,  1.3978e-02,  9.6727e-03],\n",
      "          [ 1.4297e-02, -6.6985e-04, -2.2077e-02],\n",
      "          [ 1.2398e-02,  3.5454e-02, -2.2320e-02]],\n",
      "\n",
      "         [[-2.2600e-02, -2.5331e-02, -2.3548e-02],\n",
      "          [ 6.0860e-02, -9.6779e-02,  2.4057e-02],\n",
      "          [-1.2750e-02,  9.2237e-02,  4.0152e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2160e-02,  4.2177e-02, -1.6428e-02],\n",
      "          [-2.9667e-02,  5.6865e-02,  2.5486e-02],\n",
      "          [ 4.3847e-03,  5.1188e-02,  1.0436e-02]],\n",
      "\n",
      "         [[ 2.5342e-02,  5.4374e-02,  5.3888e-02],\n",
      "          [-2.8334e-02, -2.0139e-01, -5.6358e-02],\n",
      "          [ 5.6774e-02,  7.4188e-02,  2.1585e-02]],\n",
      "\n",
      "         [[-3.1458e-08,  3.5335e-08,  5.3791e-08],\n",
      "          [-2.6896e-08,  5.1530e-08,  5.4480e-08],\n",
      "          [-3.8487e-08, -1.1234e-08, -7.5787e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2754e-01,  4.3552e-02, -6.5607e-02],\n",
      "          [-6.0462e-02,  1.5989e-01, -7.7070e-03],\n",
      "          [-9.4202e-02,  5.0750e-02, -7.8154e-02]],\n",
      "\n",
      "         [[-3.3309e-02,  1.6631e-03, -8.8497e-03],\n",
      "          [ 1.5553e-02, -5.8277e-02, -2.7437e-02],\n",
      "          [ 1.3126e-02, -3.0268e-02, -2.1661e-03]],\n",
      "\n",
      "         [[-4.2313e-03,  3.4517e-02,  3.8193e-03],\n",
      "          [ 5.4317e-02, -1.2457e-02,  3.2900e-02],\n",
      "          [ 2.2000e-04,  1.6040e-02,  1.2764e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5247e-02,  8.0748e-03,  2.0353e-02],\n",
      "          [ 1.7344e-02, -2.4320e-02, -1.5511e-04],\n",
      "          [-2.7634e-04,  2.8024e-02, -2.3777e-03]],\n",
      "\n",
      "         [[-2.3741e-02, -3.2057e-03, -5.7059e-03],\n",
      "          [-1.1582e-02,  1.7200e-03,  2.1067e-02],\n",
      "          [ 4.3606e-03, -4.6459e-02, -7.2954e-02]],\n",
      "\n",
      "         [[ 3.1002e-08,  5.3568e-08,  3.1873e-08],\n",
      "          [-1.6063e-08, -1.8072e-08, -1.9508e-09],\n",
      "          [-5.8339e-08, -4.5366e-08, -1.2395e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9689e-03, -2.6809e-02, -4.3760e-02],\n",
      "          [ 2.4518e-02, -2.8396e-02, -3.5896e-02],\n",
      "          [-1.7883e-04, -2.4661e-02, -2.0085e-02]],\n",
      "\n",
      "         [[ 2.1551e-02,  2.2789e-03, -2.5823e-02],\n",
      "          [ 2.3272e-02, -7.9333e-03, -2.0814e-03],\n",
      "          [-5.7062e-03, -2.6934e-02, -1.4421e-02]],\n",
      "\n",
      "         [[-1.9674e-02,  2.7914e-02, -2.0025e-02],\n",
      "          [ 6.3222e-02, -3.9077e-02, -3.3220e-03],\n",
      "          [-2.7434e-02,  1.1390e-02, -3.1608e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.3440e-03, -7.6970e-03, -6.4950e-02],\n",
      "          [ 1.3846e-02, -2.2803e-02, -4.6478e-02],\n",
      "          [ 2.7776e-02,  1.6080e-02, -1.3363e-02]],\n",
      "\n",
      "         [[ 4.7379e-02, -2.4982e-02, -2.7605e-02],\n",
      "          [ 7.0091e-02,  4.2084e-03, -1.0805e-01],\n",
      "          [ 1.7526e-02,  4.5647e-02,  7.8810e-03]],\n",
      "\n",
      "         [[ 2.6680e-09,  2.7671e-08,  2.4702e-08],\n",
      "          [ 6.3905e-09,  4.1020e-08,  3.3631e-08],\n",
      "          [ 5.8335e-09,  1.3334e-08,  9.6604e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5900e-03,  4.7084e-02, -8.6949e-03],\n",
      "          [-6.3011e-03,  5.9585e-02,  5.8667e-03],\n",
      "          [-2.0255e-02,  4.3285e-02,  4.5094e-03]],\n",
      "\n",
      "         [[ 1.1253e-03, -5.7461e-03, -6.8411e-03],\n",
      "          [ 6.0616e-03,  7.3295e-03, -1.1784e-02],\n",
      "          [-1.1455e-03,  5.1868e-03, -1.9867e-02]],\n",
      "\n",
      "         [[ 1.7529e-02,  4.4606e-02, -2.6595e-02],\n",
      "          [ 2.2102e-02,  4.5857e-02,  2.3347e-02],\n",
      "          [ 1.8052e-02,  5.9689e-02,  1.7129e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.9112e-02,  3.4242e-03, -1.7523e-02],\n",
      "          [-2.3682e-02,  2.2716e-02, -3.8301e-02],\n",
      "          [-1.0308e-02, -4.3802e-03, -2.3582e-02]],\n",
      "\n",
      "         [[-4.9607e-02, -3.2724e-03, -1.5345e-02],\n",
      "          [-1.3524e-02,  5.4842e-02,  1.1187e-02],\n",
      "          [-2.3549e-02, -2.8495e-02, -6.6371e-02]],\n",
      "\n",
      "         [[-4.9804e-08, -2.8211e-08, -2.0583e-08],\n",
      "          [-5.2389e-08, -2.8522e-08, -3.5099e-08],\n",
      "          [-3.2171e-08, -3.4110e-08, -4.3153e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4487e-03,  2.6532e-02, -1.1202e-02],\n",
      "          [ 7.0925e-03,  3.7903e-02, -3.2481e-02],\n",
      "          [ 4.1381e-02,  3.2329e-02,  2.8309e-03]],\n",
      "\n",
      "         [[-6.5955e-03,  1.6476e-02,  2.1810e-02],\n",
      "          [-1.2293e-02,  2.2310e-02,  1.2645e-02],\n",
      "          [-8.9897e-03,  1.1948e-03, -5.2390e-03]],\n",
      "\n",
      "         [[-2.5295e-03,  7.2689e-02, -7.8046e-03],\n",
      "          [-4.2221e-02,  7.9756e-02, -2.7738e-02],\n",
      "          [ 4.6716e-03, -5.6596e-02, -8.2261e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2235e-02,  3.5231e-03, -3.3131e-02],\n",
      "          [ 3.1048e-02,  1.6193e-02,  1.7283e-02],\n",
      "          [ 1.4446e-02,  2.4302e-02, -1.9689e-03]],\n",
      "\n",
      "         [[-2.4717e-02,  8.3009e-03, -6.1336e-02],\n",
      "          [-1.6134e-02,  5.5323e-02, -6.5029e-02],\n",
      "          [-2.4715e-02,  1.0030e-03,  3.2437e-02]],\n",
      "\n",
      "         [[ 1.8496e-08,  5.2798e-09,  4.1820e-08],\n",
      "          [ 3.7489e-08,  2.5450e-08,  3.0419e-08],\n",
      "          [ 1.1246e-08, -5.6956e-09, -2.0008e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1194e-03, -4.1052e-02, -1.0002e-02],\n",
      "          [ 2.5924e-02, -6.3819e-02,  1.3366e-02],\n",
      "          [ 2.9751e-02, -7.9476e-03,  1.4007e-02]],\n",
      "\n",
      "         [[-2.5166e-03,  2.2051e-02, -1.9967e-02],\n",
      "          [-5.9436e-02,  4.3872e-02,  2.6832e-02],\n",
      "          [-1.7509e-02,  2.4625e-02,  2.4822e-02]],\n",
      "\n",
      "         [[ 3.5832e-02, -7.0357e-02,  3.9452e-03],\n",
      "          [-2.9835e-02,  9.2727e-02,  1.9336e-02],\n",
      "          [-2.9145e-02, -9.7087e-03, -7.3388e-02]]]], requires_grad=True), 'bn1.running_mean': tensor([-0.4332, -0.1757,  0.0307, -0.7058, -1.6364, -0.7989, -0.0678, -0.1956,\n",
      "        -1.1260, -0.9578,  0.0030, -1.8265, -0.0393, -0.8680, -1.1062, -0.6359,\n",
      "        -0.9872, -0.5778, -1.3349, -0.3408, -1.1982, -1.6058, -2.1702, -0.8814,\n",
      "        -0.8175, -0.6951,  0.6542, -1.6422,  0.2811,  0.3163, -0.4123, -1.4023,\n",
      "        -1.5044, -2.5031, -2.1580, -1.3645, -0.8579, -0.2206, -2.5548, -2.2695,\n",
      "        -0.1609, -0.8552,  0.5289,  1.3492, -0.9382, -0.3356, -2.9168, -1.5967,\n",
      "        -1.8875, -1.6166, -1.9443, -2.0195, -0.9671, -1.3881, -1.8836,  0.1869,\n",
      "        -1.3487, -0.4593, -0.4542, -0.9032, -0.0768, -1.7719,  1.2484, -0.9139]), 'bn1.running_var': tensor([0.4351, 0.2044, 0.2344, 0.5559, 0.9626, 0.3484, 0.0871, 0.6851, 0.4714,\n",
      "        1.2642, 0.1519, 0.6730, 0.2430, 0.5577, 0.8701, 0.2419, 0.2052, 0.8149,\n",
      "        0.3040, 0.2617, 0.8060, 0.8007, 1.5581, 0.2404, 0.4445, 0.6765, 0.5562,\n",
      "        0.9378, 0.2584, 0.3173, 0.0962, 0.4118, 0.5197, 0.9767, 1.2703, 0.8908,\n",
      "        0.3609, 0.2227, 1.1588, 1.5965, 0.4060, 0.2559, 0.1763, 0.2797, 0.3757,\n",
      "        0.1282, 1.8280, 0.3145, 0.7419, 0.2129, 0.8122, 0.4660, 0.4065, 0.4914,\n",
      "        0.4814, 0.1697, 0.4000, 0.3867, 0.1499, 0.4137, 0.0671, 0.8303, 0.2434,\n",
      "        0.3449]), 'bn1.weight': Parameter containing:\n",
      "tensor([0.3090, 0.2147, 0.2366, 0.4259, 0.5137, 0.2181, 0.2204, 0.2300, 0.2640,\n",
      "        0.2695, 0.2138, 0.4602, 0.2661, 0.2319, 0.3900, 0.2389, 0.2660, 0.3634,\n",
      "        0.3474, 0.2477, 0.3285, 0.5349, 0.6440, 0.2275, 0.4482, 0.3078, 0.2604,\n",
      "        0.4651, 0.2179, 0.2858, 0.3426, 0.4420, 0.4450, 0.4500, 0.5516, 0.5092,\n",
      "        0.2564, 0.2634, 0.5664, 0.6410, 0.2228, 0.1986, 0.2460, 0.2242, 0.2143,\n",
      "        0.1982, 0.6368, 0.3106, 0.5049, 0.2403, 0.3065, 0.3760, 0.3794, 0.4281,\n",
      "        0.2991, 0.3326, 0.2596, 0.3345, 0.2006, 0.4351, 0.1683, 0.5149, 0.2629,\n",
      "        0.3254], requires_grad=True), 'bn1.bias': Parameter containing:\n",
      "tensor([ 0.1657,  0.2420,  0.1780, -0.0431, -0.2053,  0.1598,  0.2929,  0.0912,\n",
      "         0.1116,  0.0884,  0.1104, -0.2035,  0.1539,  0.0857, -0.1094,  0.0654,\n",
      "         0.0766, -0.2067, -0.0212,  0.1396,  0.0401, -0.2827, -0.3257, -0.0035,\n",
      "        -0.4373, -0.1248,  0.1282, -0.0874,  0.1199, -0.0829, -0.5315, -0.0780,\n",
      "        -0.3876, -0.0547, -0.1816, -0.1888,  0.1320,  0.0031, -0.2697, -0.2984,\n",
      "         0.1394,  0.2597,  0.1372,  0.0053,  0.0132,  0.3295, -0.2715, -0.0187,\n",
      "        -0.2467,  0.1579,  0.0165, -0.0890, -0.1903, -0.0787,  0.1700, -0.4832,\n",
      "         0.0619, -0.0677,  0.3125, -0.5064,  0.3138, -0.2617, -0.1545,  0.0063],\n",
      "       requires_grad=True), 'conv2.weight': Parameter containing:\n",
      "tensor([[[[ 2.5947e-02, -1.0458e-01, -4.7712e-03],\n",
      "          [-8.6223e-02, -3.3021e-01, -1.0275e-01],\n",
      "          [-5.7426e-02, -1.9074e-01, -5.4646e-02]],\n",
      "\n",
      "         [[-1.6951e-02,  2.1384e-02, -2.1074e-03],\n",
      "          [-3.2983e-03,  4.5014e-02, -1.1510e-02],\n",
      "          [-5.9602e-02,  6.4942e-03,  2.9080e-03]],\n",
      "\n",
      "         [[-4.4903e-03,  1.9637e-02,  1.3167e-02],\n",
      "          [ 1.3050e-02, -7.7471e-03,  1.1931e-02],\n",
      "          [ 1.3454e-02,  1.1103e-02,  5.5145e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2706e-03, -7.7438e-03,  2.0753e-02],\n",
      "          [-4.0024e-02, -4.0383e-02, -3.4821e-02],\n",
      "          [-2.0251e-02, -9.5164e-03,  1.3954e-02]],\n",
      "\n",
      "         [[-2.3430e-03,  3.2303e-02, -4.3342e-03],\n",
      "          [ 8.6194e-03,  1.0553e-02,  1.8074e-03],\n",
      "          [-1.2760e-02, -1.0232e-02,  4.5711e-03]],\n",
      "\n",
      "         [[ 1.5302e-02,  2.1361e-02, -7.0908e-03],\n",
      "          [-1.4221e-02,  4.5979e-02,  2.1369e-02],\n",
      "          [ 3.1312e-02,  6.6428e-02,  2.1465e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3422e-02,  4.0515e-02,  9.6680e-03],\n",
      "          [ 3.2884e-02, -2.3474e-02,  3.4642e-02],\n",
      "          [-1.2861e-02,  5.0066e-02,  5.4579e-02]],\n",
      "\n",
      "         [[ 2.8764e-02,  4.3431e-02,  2.8258e-02],\n",
      "          [ 2.8734e-02, -3.5459e-02, -5.2788e-02],\n",
      "          [-5.5119e-02, -7.1813e-02, -8.2970e-02]],\n",
      "\n",
      "         [[ 9.5293e-02,  1.2549e-01, -6.4001e-02],\n",
      "          [-4.1166e-02, -9.0480e-04,  5.1387e-02],\n",
      "          [-1.1311e-01, -7.9823e-02,  1.4373e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.6924e-03,  2.0647e-02,  1.9521e-02],\n",
      "          [-6.7352e-03,  1.2601e-04,  4.8309e-03],\n",
      "          [-6.2405e-03, -9.2119e-03, -2.5806e-04]],\n",
      "\n",
      "         [[-2.6153e-02, -2.4641e-02,  4.0970e-02],\n",
      "          [-1.9164e-02, -1.0160e-02,  3.3163e-02],\n",
      "          [ 5.4200e-03,  9.0485e-04,  6.7799e-04]],\n",
      "\n",
      "         [[ 7.7762e-03,  2.6447e-02,  6.3650e-02],\n",
      "          [-3.0608e-02,  2.4959e-02,  1.2951e-02],\n",
      "          [-2.0938e-02, -7.7342e-03, -3.8790e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0893e-02, -1.4409e-02,  1.5730e-02],\n",
      "          [ 1.6655e-02,  4.4535e-02,  6.3212e-02],\n",
      "          [ 3.4121e-02,  7.3135e-02,  5.9203e-02]],\n",
      "\n",
      "         [[ 2.3195e-03,  7.7598e-03,  2.0308e-02],\n",
      "          [ 2.0457e-02,  4.0029e-02,  3.4744e-02],\n",
      "          [-4.7356e-02, -3.7286e-02,  1.4542e-02]],\n",
      "\n",
      "         [[-2.2742e-02, -1.9000e-02, -8.4317e-03],\n",
      "          [-9.8759e-04,  2.1510e-02,  6.3959e-03],\n",
      "          [-9.4558e-03,  2.6833e-03, -3.1136e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5787e-03, -1.6056e-02, -6.4204e-04],\n",
      "          [-5.5104e-03,  1.4252e-02,  4.5000e-02],\n",
      "          [-9.2800e-03,  2.2351e-02,  4.1728e-02]],\n",
      "\n",
      "         [[ 2.5705e-02,  4.8207e-02,  7.9145e-02],\n",
      "          [-4.4350e-03,  3.8872e-03,  4.1694e-02],\n",
      "          [ 8.0536e-04, -1.0601e-02,  9.2706e-03]],\n",
      "\n",
      "         [[-3.3892e-02,  9.3543e-03,  4.1746e-02],\n",
      "          [-1.6470e-02,  3.9542e-03,  6.2438e-02],\n",
      "          [-3.1055e-02, -3.6302e-03,  7.0817e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.1044e-05, -9.0020e-03, -2.6998e-03],\n",
      "          [ 3.0072e-03,  1.1579e-02,  1.5214e-02],\n",
      "          [ 3.4832e-03,  1.1353e-05,  1.6320e-02]],\n",
      "\n",
      "         [[-2.6334e-02,  2.1967e-02, -6.0039e-02],\n",
      "          [ 4.4519e-02,  1.3203e-01, -9.1163e-03],\n",
      "          [ 5.4242e-02,  1.3726e-01,  2.7454e-02]],\n",
      "\n",
      "         [[ 1.7122e-02,  3.7646e-03,  1.4872e-02],\n",
      "          [ 1.2092e-02,  1.1319e-02,  3.4667e-02],\n",
      "          [ 8.1790e-03, -2.0805e-02,  2.7143e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0111e-02, -1.0526e-02,  2.8394e-02],\n",
      "          [-2.5112e-02, -2.2196e-02,  3.7229e-02],\n",
      "          [-3.8220e-02, -4.6644e-02,  1.5660e-02]],\n",
      "\n",
      "         [[-2.5913e-03, -2.4307e-02,  1.0611e-02],\n",
      "          [-2.1730e-02, -4.3938e-02, -7.1536e-03],\n",
      "          [-2.5171e-02, -5.9467e-02, -2.5577e-02]],\n",
      "\n",
      "         [[ 2.8652e-02,  2.5850e-04,  1.1416e-03],\n",
      "          [ 3.7812e-02, -1.1271e-03,  9.6027e-03],\n",
      "          [ 3.9350e-02,  1.0134e-02,  1.0449e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.9305e-03,  7.0872e-03,  2.1412e-02],\n",
      "          [-6.0065e-02,  1.4147e-03,  9.7281e-02],\n",
      "          [-6.0130e-02, -2.1725e-02,  3.6863e-02]],\n",
      "\n",
      "         [[ 2.8024e-02,  2.6183e-02, -2.3027e-02],\n",
      "          [ 5.1900e-02, -2.0588e-03, -1.0940e-01],\n",
      "          [-3.2729e-02, -6.2752e-03,  8.0630e-03]],\n",
      "\n",
      "         [[-1.8062e-02, -1.9510e-02,  4.3163e-02],\n",
      "          [ 4.6080e-02,  2.9494e-02,  4.0844e-02],\n",
      "          [ 5.9607e-03, -6.5891e-03, -6.4623e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2193e-02,  8.4653e-03,  3.6764e-03],\n",
      "          [ 1.7549e-02,  2.1971e-02, -4.5108e-03],\n",
      "          [ 2.1124e-02,  3.4591e-02, -1.6310e-02]],\n",
      "\n",
      "         [[ 3.8144e-02,  4.8395e-02, -9.5556e-02],\n",
      "          [ 1.8923e-02,  1.1341e-02, -7.6311e-02],\n",
      "          [ 4.7358e-03,  3.2138e-02, -7.4777e-02]],\n",
      "\n",
      "         [[-1.9031e-02, -3.2568e-02, -3.8251e-02],\n",
      "          [ 1.0705e-02,  2.3121e-03, -7.5078e-02],\n",
      "          [ 3.3316e-02,  3.5515e-02, -2.1023e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.3330e-01,  7.4683e-02, -3.8624e-03],\n",
      "          [ 9.1377e-02,  8.2415e-02,  3.9469e-02],\n",
      "          [-1.8265e-02, -5.9943e-02,  8.9354e-02]],\n",
      "\n",
      "         [[ 1.5566e-02, -4.1716e-02,  1.0633e-02],\n",
      "          [ 7.2644e-03,  3.1934e-02,  1.2732e-03],\n",
      "          [-2.0851e-02, -3.7593e-03, -7.0170e-02]],\n",
      "\n",
      "         [[-6.6139e-02,  1.0627e-01,  1.9590e-02],\n",
      "          [ 5.4987e-02, -1.5552e-01, -1.8819e-02],\n",
      "          [-4.2554e-03,  4.4964e-02, -2.4632e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1691e-02, -4.5531e-02, -9.1721e-03],\n",
      "          [ 4.3995e-02,  4.5703e-02, -7.0108e-02],\n",
      "          [ 1.1388e-02,  4.4678e-02, -4.5953e-02]],\n",
      "\n",
      "         [[ 4.3432e-03,  2.3194e-02, -2.1895e-02],\n",
      "          [-8.0216e-02, -5.7606e-02, -9.8455e-03],\n",
      "          [-3.3285e-02, -1.1468e-01, -2.3779e-02]],\n",
      "\n",
      "         [[-6.3785e-02, -2.4485e-02, -4.9061e-02],\n",
      "          [-6.1594e-02,  1.0328e-01,  5.9685e-03],\n",
      "          [ 8.1863e-02, -3.0314e-02, -4.6373e-03]]]], requires_grad=True), 'bn2.running_mean': tensor([ 1.6767e-01,  5.1604e-03,  7.8681e-01,  1.6696e-01,  4.7745e-01,\n",
      "        -3.6223e-02, -5.7831e-02,  2.0108e-03, -3.4202e-01,  6.7421e-02,\n",
      "        -9.7042e-02, -9.9979e-02, -6.5909e-02, -3.8458e-02, -7.0890e-02,\n",
      "        -2.2176e-01, -1.3434e-01,  1.1979e-01, -6.0160e-02,  6.1843e-04,\n",
      "         8.6362e-02, -1.4662e-01,  3.5369e-02, -1.5391e-01, -4.1574e-02,\n",
      "        -4.3171e-01,  3.2966e-02, -7.9720e-02, -5.8684e-01, -2.4614e-01,\n",
      "        -1.5049e-01, -4.0124e-01, -2.1874e-01, -6.3512e-01,  6.9792e-02,\n",
      "         1.4116e-01,  2.7538e-01, -5.6446e-01, -1.1135e-01, -2.4137e-01,\n",
      "        -1.3131e-01, -2.1504e-02,  1.2639e-01, -1.6843e-01,  1.6926e-01,\n",
      "        -4.6841e-01, -6.9076e-01,  2.0441e-01,  1.4749e-03, -5.4254e-02,\n",
      "        -1.4867e-01,  1.2616e-01, -1.1453e-01, -1.5967e-01,  1.2299e-01,\n",
      "        -1.6053e-01, -2.2562e-01, -9.9545e-02, -1.6210e-01,  3.2296e-01,\n",
      "        -5.5390e-03,  1.0911e-01,  7.8114e-02,  1.2128e-02]), 'bn2.running_var': tensor([0.1130, 0.0412, 0.0335, 0.1282, 0.2084, 0.0307, 0.0606, 0.0737, 0.0313,\n",
      "        0.0409, 0.1376, 0.0399, 0.0437, 0.0282, 0.1588, 0.0288, 0.0837, 0.0799,\n",
      "        0.0177, 0.1839, 0.0884, 0.3054, 0.1512, 0.0394, 0.0374, 0.0969, 0.1719,\n",
      "        0.0610, 0.0607, 0.1560, 0.0448, 0.1236, 0.0464, 0.1005, 0.0498, 0.0481,\n",
      "        0.0450, 0.1229, 0.0623, 0.0381, 0.0229, 0.1227, 0.1656, 0.1047, 0.1316,\n",
      "        0.1834, 0.0622, 0.1272, 0.1929, 0.0419, 0.0263, 0.2623, 0.0712, 0.1442,\n",
      "        0.0937, 0.0983, 0.1163, 0.1511, 0.1009, 0.0342, 0.1854, 0.0698, 0.0631,\n",
      "        0.0350]), 'bn2.weight': Parameter containing:\n",
      "tensor([0.2496, 0.2198, 0.2756, 0.6073, 0.2654, 0.2942, 0.1136, 0.4425, 0.2868,\n",
      "        0.2974, 0.2506, 0.4103, 0.4855, 0.3383, 0.4670, 0.1772, 0.2171, 0.5025,\n",
      "        0.2263, 0.3667, 0.4867, 0.4586, 0.4652, 0.2200, 0.1510, 0.2761, 0.3813,\n",
      "        0.2803, 0.2382, 0.3953, 0.3032, 0.3163, 0.2025, 0.2323, 0.2003, 0.1661,\n",
      "        0.4690, 0.3476, 0.3414, 0.2274, 0.2485, 0.2356, 0.2726, 0.4657, 0.3429,\n",
      "        0.2465, 0.4674, 0.2812, 0.6241, 0.4152, 0.3403, 0.4218, 0.1152, 0.2985,\n",
      "        0.5802, 0.2795, 0.4706, 0.4517, 0.4303, 0.2749, 0.3427, 0.1137, 0.5069,\n",
      "        0.4370], requires_grad=True), 'bn2.bias': Parameter containing:\n",
      "tensor([ 2.2752e-01,  8.6747e-03, -6.7346e-02, -6.8779e-02,  3.5977e-01,\n",
      "        -2.0167e-01, -4.8431e-05,  2.3735e-02,  3.9549e-01,  3.7079e-02,\n",
      "         6.8793e-03,  2.7578e-01, -7.0272e-02, -2.3970e-01, -8.1753e-02,\n",
      "        -9.4132e-02, -1.4544e-01,  3.7301e-02, -3.6174e-01, -3.9561e-01,\n",
      "        -4.0789e-01,  3.5559e-03, -2.7878e-01, -3.5299e-02, -7.0281e-02,\n",
      "         2.1005e-01, -4.6362e-03, -1.9665e-01, -2.8066e-01, -1.6540e-02,\n",
      "         2.6452e-01, -8.9359e-02, -2.1046e-01, -1.3026e-01,  1.7215e-01,\n",
      "         5.3403e-02, -2.2295e-01, -4.8033e-02,  2.4572e-01,  2.0950e-01,\n",
      "         1.6220e-01,  1.1370e-01,  1.1457e-01, -1.4870e-01, -3.2150e-02,\n",
      "        -3.0549e-01,  4.9125e-01,  1.0873e-01,  1.2779e-02,  1.0044e-01,\n",
      "         4.1553e-01, -1.4710e-02,  2.3922e-02,  9.9812e-02, -1.7273e-01,\n",
      "         1.0078e-01, -1.4564e-01, -2.2735e-01,  1.3637e-01,  2.0127e-01,\n",
      "        -5.7430e-02,  2.3530e-01, -1.1299e-01,  3.0933e-01],\n",
      "       requires_grad=True)}\n",
      "Done loading BasicBlock weights!\n",
      "idx: 1, layer type: <class '__main__.BasicBlock'>\n",
      "True\n",
      "{'conv1.weight': Parameter containing:\n",
      "tensor([[[[ 1.9712e-02, -5.2562e-03, -3.7619e-03],\n",
      "          [-1.9635e-02, -1.2336e-02, -3.5196e-02],\n",
      "          [ 5.0761e-02,  7.5668e-02,  4.3344e-02]],\n",
      "\n",
      "         [[ 1.4160e-02, -8.6094e-03, -1.0541e-02],\n",
      "          [-4.2586e-02, -2.3814e-02, -5.4694e-02],\n",
      "          [-1.4018e-03,  4.6720e-02,  5.0898e-02]],\n",
      "\n",
      "         [[ 2.1559e-02,  4.1633e-03, -9.7118e-03],\n",
      "          [-9.3201e-03, -2.5432e-02, -2.8274e-02],\n",
      "          [-3.0107e-02, -4.8230e-02, -2.6001e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4300e-03,  9.1875e-02,  3.1938e-03],\n",
      "          [-1.7945e-02,  5.7266e-02, -8.4098e-03],\n",
      "          [-3.4961e-02, -2.3296e-02, -3.5089e-02]],\n",
      "\n",
      "         [[ 2.5603e-02, -3.1689e-02, -5.4160e-02],\n",
      "          [ 6.9736e-02, -1.0716e-02, -6.8034e-02],\n",
      "          [ 3.5578e-02,  3.4749e-02, -1.9334e-02]],\n",
      "\n",
      "         [[-6.5420e-02, -4.6427e-03, -2.3362e-02],\n",
      "          [ 7.5833e-02,  9.1174e-03, -4.9701e-02],\n",
      "          [ 6.2944e-02, -9.8735e-02,  3.3158e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0557e-03, -3.0753e-02,  1.1953e-02],\n",
      "          [-3.2539e-02, -6.2846e-03, -2.0235e-02],\n",
      "          [ 4.7996e-03, -2.1462e-02, -4.1557e-03]],\n",
      "\n",
      "         [[ 1.7163e-02, -2.3303e-03,  7.3972e-02],\n",
      "          [-3.2105e-02, -7.7536e-02, -1.2648e-02],\n",
      "          [ 3.8985e-02, -4.3170e-02,  1.0904e-02]],\n",
      "\n",
      "         [[-2.9643e-02, -5.8534e-02, -5.9736e-02],\n",
      "          [-2.9437e-02, -3.6441e-02, -1.2380e-02],\n",
      "          [-2.2775e-02, -2.4485e-03, -1.6124e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6830e-02,  1.4267e-02,  6.2658e-02],\n",
      "          [ 3.0585e-04, -5.3241e-03,  3.2786e-03],\n",
      "          [ 2.1097e-02, -2.3189e-02,  1.2102e-02]],\n",
      "\n",
      "         [[-6.1182e-02, -2.9227e-02,  2.0036e-02],\n",
      "          [-7.6089e-02, -7.7057e-02,  8.6544e-02],\n",
      "          [-3.9228e-02, -3.2361e-02, -8.8970e-02]],\n",
      "\n",
      "         [[-1.3372e-01,  8.8362e-02,  8.3836e-02],\n",
      "          [-1.1688e-02,  4.3156e-01, -3.3629e-03],\n",
      "          [-2.3925e-02, -1.0092e-01, -1.0184e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0165e-02,  4.3042e-02,  2.7325e-03],\n",
      "          [ 3.5269e-02, -1.5504e-02, -3.5011e-02],\n",
      "          [-1.7164e-02, -2.6827e-02, -3.3946e-02]],\n",
      "\n",
      "         [[ 4.5439e-02,  5.1585e-02,  1.8321e-02],\n",
      "          [-3.9647e-02,  2.3956e-02, -2.6609e-02],\n",
      "          [-3.0358e-02, -6.4729e-02,  2.5834e-02]],\n",
      "\n",
      "         [[ 3.8105e-02,  4.0986e-02,  4.1005e-02],\n",
      "          [ 1.7584e-02, -1.6494e-02, -3.2716e-02],\n",
      "          [ 5.5886e-03, -1.7068e-02, -3.0605e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3694e-01, -1.4074e-01,  5.1423e-02],\n",
      "          [-1.2521e-01, -1.3128e-01,  7.5733e-02],\n",
      "          [-4.5032e-02, -1.7081e-02,  7.1252e-02]],\n",
      "\n",
      "         [[ 6.3381e-02,  1.5874e-02, -2.7322e-02],\n",
      "          [ 8.0356e-02,  3.6104e-02, -2.8506e-02],\n",
      "          [ 2.6638e-02,  2.2021e-02,  3.2345e-02]],\n",
      "\n",
      "         [[-1.2068e-03, -4.6179e-02, -1.5351e-02],\n",
      "          [-1.1276e-02,  1.9200e-02,  3.4336e-02],\n",
      "          [ 1.6540e-02, -7.8592e-03, -2.5392e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.3384e-02,  6.9963e-02,  1.0745e-02],\n",
      "          [-1.7518e-02, -5.3524e-02, -6.4960e-02],\n",
      "          [ 3.4248e-04, -4.5557e-02, -4.7336e-02]],\n",
      "\n",
      "         [[-5.1031e-03,  7.9784e-03, -8.6553e-04],\n",
      "          [-1.6557e-03,  1.4661e-02,  5.3365e-03],\n",
      "          [-3.1784e-02, -6.6940e-02, -4.6889e-02]],\n",
      "\n",
      "         [[-1.1775e-02,  7.2759e-03,  7.6622e-03],\n",
      "          [-6.1288e-02, -5.2078e-02, -4.5152e-02],\n",
      "          [-8.6584e-02, -9.7381e-02, -1.0405e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1243e-02,  6.2456e-02,  2.5188e-02],\n",
      "          [-2.2911e-02, -2.1100e-03, -2.7573e-02],\n",
      "          [ 4.6557e-02,  6.4980e-02,  3.1879e-02]],\n",
      "\n",
      "         [[ 6.2867e-03,  2.4255e-02,  8.9674e-02],\n",
      "          [-7.7718e-03, -5.4311e-02, -4.6843e-02],\n",
      "          [-6.7499e-03, -6.6857e-02, -4.9842e-02]],\n",
      "\n",
      "         [[ 4.7326e-03, -3.9533e-02,  1.1500e-03],\n",
      "          [-2.7957e-02, -1.3466e-01, -6.0753e-02],\n",
      "          [-3.2010e-03,  7.2213e-02,  1.1009e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3763e-02, -1.7876e-02, -7.4843e-03],\n",
      "          [ 1.6239e-02,  5.4479e-04, -3.3735e-02],\n",
      "          [-2.2854e-02, -1.4316e-03,  1.1010e-02]],\n",
      "\n",
      "         [[ 5.2277e-03, -2.5941e-03,  5.9594e-03],\n",
      "          [-2.9058e-03, -7.3409e-03,  3.0652e-02],\n",
      "          [ 7.5540e-02,  6.6445e-03,  2.5518e-03]],\n",
      "\n",
      "         [[-6.5970e-02, -4.1286e-02, -3.0278e-02],\n",
      "          [-3.5108e-02, -3.9099e-02, -1.6818e-02],\n",
      "          [-1.0224e-02, -8.6995e-03, -5.9939e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1233e-02, -2.4559e-02, -7.4436e-03],\n",
      "          [-4.3734e-03, -3.2864e-02, -3.3453e-02],\n",
      "          [ 8.9269e-03, -1.7646e-02,  3.8375e-04]],\n",
      "\n",
      "         [[-7.8930e-02, -7.2940e-02, -6.7911e-02],\n",
      "          [-8.4146e-02, -8.3657e-02,  5.3666e-02],\n",
      "          [-3.5577e-02, -3.6835e-02,  5.8987e-03]],\n",
      "\n",
      "         [[ 8.3767e-02,  8.0476e-05,  7.2164e-02],\n",
      "          [-6.4219e-02, -1.2661e-01,  4.6026e-02],\n",
      "          [ 9.3033e-02, -4.7521e-02,  3.6777e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1012e-02,  1.3361e-03, -5.8616e-02],\n",
      "          [ 4.2461e-02,  2.9437e-03, -2.0445e-02],\n",
      "          [ 7.6097e-02,  5.2504e-02, -5.5636e-03]],\n",
      "\n",
      "         [[ 2.2046e-02,  4.0888e-03,  1.4645e-02],\n",
      "          [-7.7532e-02, -1.1912e-01, -7.0892e-02],\n",
      "          [-1.0618e-02, -3.2121e-02, -2.3969e-02]],\n",
      "\n",
      "         [[-2.1612e-02, -2.6110e-03, -3.1664e-02],\n",
      "          [-3.2892e-02, -3.9771e-02, -5.1463e-02],\n",
      "          [-2.6150e-02, -3.6554e-02, -2.3315e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4600e-03,  8.4181e-02,  2.3199e-02],\n",
      "          [ 5.7595e-02,  1.3036e-01,  3.2172e-02],\n",
      "          [-2.2774e-03,  4.2065e-02, -4.8619e-02]],\n",
      "\n",
      "         [[ 3.1533e-02, -4.3655e-02,  2.0361e-02],\n",
      "          [ 3.9973e-03, -5.1430e-02, -6.3839e-02],\n",
      "          [ 6.4002e-03,  4.5347e-02,  4.7346e-02]],\n",
      "\n",
      "         [[-9.1818e-02,  1.0264e-02,  9.6565e-02],\n",
      "          [-2.1635e-03, -2.3452e-02, -5.9038e-02],\n",
      "          [ 1.9402e-02,  2.8854e-02, -9.6113e-02]]]], requires_grad=True), 'bn1.running_mean': tensor([-0.6534,  0.9240, -1.3403, -0.7395, -0.5830, -1.6717, -0.3376,  0.1913,\n",
      "        -0.4565, -0.7877, -0.3756, -0.2295, -1.7003, -0.6135,  0.5422, -0.1072,\n",
      "        -0.2315, -0.3775, -1.8026, -0.7210, -0.0288, -1.2585, -1.8144,  0.0504,\n",
      "        -0.0739, -1.5506, -1.5092, -1.0623,  0.1706,  0.1527,  0.3983, -2.9065,\n",
      "        -0.9070, -0.2983, -1.8404, -2.3956,  0.2241, -0.0760, -0.9525, -1.4632,\n",
      "         0.7657, -0.3832,  0.8590, -1.3211, -1.2599, -0.1220, -0.2230,  0.5071,\n",
      "         1.0262, -0.5969, -0.0104, -1.4013, -0.4267, -0.9979, -1.9458,  0.1991,\n",
      "        -0.8841, -0.8302, -0.3076, -2.0759, -1.2645,  0.2679,  0.4349, -1.2568]), 'bn1.running_var': tensor([0.7111, 0.5543, 0.6143, 0.5148, 0.2840, 0.4924, 0.3536, 0.3939, 0.2511,\n",
      "        0.4859, 0.1803, 0.7468, 0.4225, 0.3686, 0.1719, 0.2777, 0.3676, 0.2311,\n",
      "        0.3515, 0.4917, 0.1393, 0.1732, 0.6248, 0.3038, 0.1599, 0.5246, 0.2410,\n",
      "        0.5096, 0.5251, 0.5369, 0.1800, 1.0623, 0.4006, 0.2060, 0.5194, 0.4981,\n",
      "        0.4250, 0.2616, 0.8252, 0.4991, 0.3290, 0.3642, 0.2716, 0.6520, 0.4492,\n",
      "        0.2753, 0.3377, 0.3167, 0.3830, 0.4624, 0.4098, 0.5566, 0.5048, 0.4747,\n",
      "        0.6820, 0.4387, 0.3506, 0.2995, 0.5595, 0.6855, 0.5260, 0.6478, 0.4960,\n",
      "        0.5449]), 'bn1.weight': Parameter containing:\n",
      "tensor([0.3910, 0.4375, 0.3746, 0.3990, 0.3404, 0.3503, 0.2618, 0.2707, 0.2865,\n",
      "        0.4308, 0.1895, 0.3041, 0.3837, 0.2944, 0.2105, 0.3304, 0.2943, 0.2887,\n",
      "        0.2060, 0.4627, 0.2335, 0.1831, 0.4489, 0.2830, 0.3389, 0.2997, 0.3503,\n",
      "        0.2735, 0.3908, 0.2817, 0.2636, 0.4462, 0.3282, 0.3776, 0.4471, 0.3878,\n",
      "        0.2516, 0.3172, 0.3661, 0.3166, 0.3818, 0.3128, 0.2274, 0.3627, 0.2902,\n",
      "        0.2381, 0.2988, 0.2469, 0.3840, 0.2886, 0.3197, 0.2879, 0.3218, 0.4559,\n",
      "        0.3500, 0.2420, 0.3396, 0.3519, 0.3839, 0.3806, 0.4039, 0.2826, 0.4594,\n",
      "        0.3342], requires_grad=True), 'bn1.bias': Parameter containing:\n",
      "tensor([-0.0997, -0.4755, -0.0474, -0.2698, -0.0834, -0.0072,  0.0474,  0.1022,\n",
      "        -0.0170, -0.1471,  0.2307,  0.1447, -0.1775,  0.0273,  0.1559, -0.1836,\n",
      "         0.1238, -0.1522,  0.0554, -0.2881, -0.2606,  0.2316, -0.3242, -0.0219,\n",
      "        -0.2645,  0.0576, -0.2465,  0.0481, -0.3530,  0.0950, -0.1862, -0.1707,\n",
      "        -0.0161, -0.2604, -0.3145, -0.1083,  0.0659, -0.1427, -0.0570, -0.0076,\n",
      "        -0.3006, -0.0744, -0.0683, -0.1104,  0.0253,  0.0489, -0.2515,  0.1150,\n",
      "        -0.3783,  0.0846, -0.0368,  0.1439, -0.0468, -0.3087, -0.0240,  0.1397,\n",
      "        -0.0908, -0.1795, -0.1129, -0.0793, -0.1491,  0.0594, -0.4433, -0.0138],\n",
      "       requires_grad=True), 'conv2.weight': Parameter containing:\n",
      "tensor([[[[-2.1574e-02, -4.5688e-03,  4.5483e-03],\n",
      "          [-8.1870e-03,  4.1740e-02,  2.3010e-02],\n",
      "          [-8.9283e-03,  5.7352e-02,  2.9818e-02]],\n",
      "\n",
      "         [[ 5.8627e-02,  4.2864e-02,  4.4912e-02],\n",
      "          [ 2.2281e-02, -1.2969e-02,  7.6099e-03],\n",
      "          [ 4.5373e-02,  3.0712e-02,  3.7700e-02]],\n",
      "\n",
      "         [[-1.5456e-02, -3.8692e-02, -4.6010e-02],\n",
      "          [-2.3123e-02,  2.8293e-02,  4.7790e-03],\n",
      "          [-2.0328e-02,  1.3756e-02,  2.5883e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1302e-02,  4.2291e-02,  5.7833e-02],\n",
      "          [ 4.5210e-02,  5.5850e-02,  1.4318e-02],\n",
      "          [ 1.4241e-02,  1.7968e-02,  1.4344e-02]],\n",
      "\n",
      "         [[ 4.6012e-03,  1.2566e-02,  4.8931e-02],\n",
      "          [-6.5754e-03, -2.6431e-02,  1.5855e-02],\n",
      "          [ 1.3192e-02,  1.9011e-02,  1.3842e-02]],\n",
      "\n",
      "         [[ 6.1983e-02,  6.9919e-02,  6.1035e-02],\n",
      "          [ 6.1253e-02,  9.9557e-02,  5.9060e-02],\n",
      "          [ 5.8298e-02,  8.1652e-02,  8.1499e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0088e-02, -1.2959e-02,  9.7798e-03],\n",
      "          [ 5.5408e-02,  4.3501e-02,  5.6983e-02],\n",
      "          [ 5.3427e-02,  3.5118e-02,  3.6782e-02]],\n",
      "\n",
      "         [[ 2.4442e-03, -3.0207e-02, -1.0377e-02],\n",
      "          [-4.5297e-02, -4.5318e-02,  5.4623e-03],\n",
      "          [-4.4762e-02, -1.5508e-02,  6.9745e-03]],\n",
      "\n",
      "         [[ 3.9658e-02,  3.6838e-02,  5.8796e-03],\n",
      "          [ 2.3207e-02,  3.9240e-03, -2.0887e-02],\n",
      "          [-1.4829e-02,  5.3606e-03,  1.7404e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2160e-02,  5.9042e-02,  4.8433e-02],\n",
      "          [-2.6464e-02, -8.0667e-03, -1.0359e-02],\n",
      "          [-2.6699e-02, -9.5411e-03, -2.8902e-02]],\n",
      "\n",
      "         [[-2.9235e-02, -3.9078e-02, -4.4955e-02],\n",
      "          [-2.0346e-02, -4.4891e-02, -3.7477e-02],\n",
      "          [ 1.9653e-02, -1.5562e-03, -5.8245e-03]],\n",
      "\n",
      "         [[-5.0696e-02, -4.8902e-02,  9.1631e-03],\n",
      "          [ 5.1668e-03,  2.0509e-02,  6.6874e-02],\n",
      "          [ 2.8934e-02,  4.6717e-02,  2.1371e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1744e-02, -2.8354e-02, -3.2557e-02],\n",
      "          [ 3.0519e-02,  1.8536e-02,  1.5244e-02],\n",
      "          [ 1.3832e-03,  1.7051e-02,  3.2020e-02]],\n",
      "\n",
      "         [[-3.6293e-02,  1.0914e-02,  4.5371e-02],\n",
      "          [ 1.3399e-02,  6.4272e-02,  8.8210e-02],\n",
      "          [ 4.6697e-02,  9.9653e-02,  8.7606e-02]],\n",
      "\n",
      "         [[-2.4336e-02, -2.9627e-02,  1.9537e-02],\n",
      "          [-3.3412e-02, -2.2290e-02, -2.8879e-02],\n",
      "          [ 1.4765e-02,  1.7234e-02, -1.8185e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9859e-02, -7.1075e-02, -5.8546e-02],\n",
      "          [ 2.2902e-02,  1.1184e-02, -2.3654e-02],\n",
      "          [ 8.1897e-02,  1.1996e-01,  9.3242e-02]],\n",
      "\n",
      "         [[ 3.1984e-02,  7.4931e-02,  6.6020e-02],\n",
      "          [ 2.8490e-02,  1.1931e-01,  1.2100e-01],\n",
      "          [ 7.9259e-04,  4.3812e-02,  4.4648e-02]],\n",
      "\n",
      "         [[ 3.2748e-02,  4.1444e-02, -8.1932e-03],\n",
      "          [ 4.5541e-02,  2.9426e-02, -8.5440e-03],\n",
      "          [ 1.1634e-04,  1.8045e-03,  1.4826e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.4144e-02, -8.3106e-02, -5.3073e-02],\n",
      "          [ 3.2124e-02,  1.0286e-02,  2.4409e-02],\n",
      "          [ 6.1606e-03, -1.9455e-02,  4.0534e-02]],\n",
      "\n",
      "         [[ 5.6026e-04,  9.6961e-03,  2.5010e-03],\n",
      "          [ 7.1679e-03, -1.7535e-02, -2.3857e-02],\n",
      "          [-9.8745e-03, -1.8550e-02,  1.7301e-03]],\n",
      "\n",
      "         [[ 4.3882e-03,  4.2049e-02,  7.5950e-02],\n",
      "          [-6.5610e-02, -3.6130e-02, -1.9404e-02],\n",
      "          [-3.8091e-02, -2.6749e-02, -1.3865e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5593e-02, -4.6050e-02, -2.2809e-02],\n",
      "          [-9.7648e-03,  2.4910e-03,  2.4503e-02],\n",
      "          [ 2.0381e-02,  5.2393e-02,  6.9019e-02]],\n",
      "\n",
      "         [[ 9.3306e-04,  1.2483e-02, -1.1817e-02],\n",
      "          [-1.2627e-02, -1.8756e-02, -1.4144e-03],\n",
      "          [-5.2490e-03, -4.6126e-03, -1.3224e-02]],\n",
      "\n",
      "         [[ 7.4689e-04, -1.0135e-02, -7.8264e-03],\n",
      "          [ 1.2491e-02, -2.5865e-02,  4.0514e-02],\n",
      "          [ 5.8855e-03,  4.5990e-02,  1.0651e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2262e-02, -1.5378e-02,  1.3862e-03],\n",
      "          [ 4.1166e-02, -2.4944e-02, -2.6686e-02],\n",
      "          [-1.7423e-02,  5.2690e-03, -2.1861e-02]],\n",
      "\n",
      "         [[-3.1207e-02, -3.3025e-02,  2.2114e-02],\n",
      "          [-2.4009e-02,  1.2988e-02,  2.2430e-02],\n",
      "          [ 1.0332e-02,  4.3601e-03,  4.7321e-03]],\n",
      "\n",
      "         [[ 2.0182e-02,  6.1569e-02, -2.8771e-02],\n",
      "          [ 5.8231e-02,  4.6767e-02, -2.8417e-05],\n",
      "          [ 3.7545e-02, -4.5886e-02,  1.5849e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0431e-03, -3.6082e-03,  7.1986e-03],\n",
      "          [ 2.4895e-02,  6.1671e-03, -3.2427e-02],\n",
      "          [ 7.2338e-03,  2.2406e-03, -5.3330e-02]],\n",
      "\n",
      "         [[ 2.8072e-02, -1.0571e-02, -1.3854e-02],\n",
      "          [-1.0879e-02,  6.1929e-03, -5.6713e-03],\n",
      "          [-2.6083e-02,  8.1861e-03, -3.2873e-02]],\n",
      "\n",
      "         [[-3.1032e-02, -6.0485e-02, -2.5583e-02],\n",
      "          [-4.6239e-02, -2.2805e-02, -7.7678e-03],\n",
      "          [-9.4698e-03,  4.0247e-03, -4.8637e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3128e-02, -5.6038e-02, -3.4572e-02],\n",
      "          [ 1.0638e-03,  5.7929e-02, -7.6970e-03],\n",
      "          [-3.0103e-02,  3.5573e-02, -1.8143e-02]],\n",
      "\n",
      "         [[ 9.6840e-02, -1.1186e-01, -7.8766e-02],\n",
      "          [-1.0444e-01, -1.0851e-01, -1.9553e-01],\n",
      "          [-1.1986e-01, -7.1474e-02,  3.6750e-02]],\n",
      "\n",
      "         [[-2.2194e-02,  6.0298e-03,  5.6914e-02],\n",
      "          [-4.8342e-02,  7.8893e-02, -5.1026e-02],\n",
      "          [-5.1294e-02, -5.7434e-02, -1.9178e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4896e-02, -8.1267e-02,  5.1794e-02],\n",
      "          [-8.3985e-02, -5.7778e-02,  6.7891e-02],\n",
      "          [ 2.3837e-02,  3.8954e-02,  4.1141e-02]],\n",
      "\n",
      "         [[ 4.6446e-03,  2.7367e-02, -2.3154e-02],\n",
      "          [ 2.0675e-02,  2.3429e-02,  6.4380e-04],\n",
      "          [-5.2222e-02, -1.4854e-02, -2.5150e-02]],\n",
      "\n",
      "         [[ 2.1291e-02,  1.2736e-02,  8.4553e-03],\n",
      "          [-8.2932e-02,  7.2067e-02,  1.3107e-01],\n",
      "          [ 8.5491e-03,  1.3677e-01,  3.9867e-02]]]], requires_grad=True), 'bn2.running_mean': tensor([-0.0555, -0.2037,  0.7682, -0.0659,  0.4746, -0.0462, -0.0896,  0.0405,\n",
      "        -0.2446, -0.3079,  0.2418, -0.0135, -0.0139, -0.5716,  0.1631, -0.1234,\n",
      "        -0.0607, -0.0682,  0.0326,  0.0245, -0.1008,  0.0646,  0.0028, -0.0101,\n",
      "        -0.0145,  0.0377, -0.0842,  0.0183, -0.5056, -0.0529, -0.0573, -0.1212,\n",
      "        -0.3578, -0.2472, -0.3403,  0.0570, -0.2512, -0.2658, -0.1210, -0.0369,\n",
      "        -0.0996,  0.2838,  0.1478, -0.1105, -0.4597, -0.1867, -0.2858,  0.1237,\n",
      "        -0.1291, -0.2389,  0.0203,  0.1081, -0.2310, -0.0848, -0.0316,  0.2546,\n",
      "         0.0597, -0.1729, -0.0190,  0.1898,  0.0823,  0.0380, -0.0429,  0.1392]), 'bn2.running_var': tensor([0.0485, 0.1034, 0.0663, 0.0458, 0.1147, 0.0534, 0.0654, 0.0467, 0.0442,\n",
      "        0.0820, 0.0332, 0.0400, 0.0379, 0.0849, 0.0409, 0.0282, 0.0821, 0.0699,\n",
      "        0.0327, 0.0497, 0.0506, 0.1060, 0.0921, 0.0300, 0.0170, 0.0383, 0.0358,\n",
      "        0.0383, 0.0745, 0.0579, 0.0390, 0.0504, 0.0494, 0.0617, 0.0458, 0.0347,\n",
      "        0.0525, 0.0575, 0.0475, 0.0354, 0.0658, 0.0336, 0.0437, 0.0734, 0.0574,\n",
      "        0.0596, 0.0452, 0.0403, 0.0789, 0.0551, 0.0328, 0.0775, 0.0722, 0.0390,\n",
      "        0.0501, 0.0394, 0.0454, 0.0450, 0.0899, 0.0297, 0.0527, 0.0184, 0.0526,\n",
      "        0.0340]), 'bn2.weight': Parameter containing:\n",
      "tensor([0.2560, 0.5690, 0.4042, 0.5130, 0.2178, 0.4940, 0.3315, 0.5510, 0.4354,\n",
      "        0.5291, 0.2081, 0.4735, 0.5945, 0.5645, 0.2761, 0.2571, 0.4853, 0.6240,\n",
      "        0.4370, 0.2308, 0.4970, 0.3157, 0.5706, 0.2162, 0.1932, 0.1448, 0.2218,\n",
      "        0.2389, 0.5871, 0.3501, 0.4109, 0.3199, 0.5808, 0.3281, 0.2723, 0.1971,\n",
      "        0.6139, 0.4075, 0.6304, 0.3874, 0.7605, 0.2111, 0.3071, 0.4603, 0.3099,\n",
      "        0.1914, 0.4431, 0.2537, 0.5745, 0.6459, 0.3914, 0.3090, 0.6782, 0.1937,\n",
      "        0.5814, 0.2570, 0.3514, 0.2124, 0.5794, 0.3415, 0.2051, 0.0715, 0.4090,\n",
      "        0.4416], requires_grad=True), 'bn2.bias': Parameter containing:\n",
      "tensor([-0.1778, -0.1287,  0.0349, -0.1452,  0.1864, -0.1413, -0.4201, -0.1334,\n",
      "         0.2183, -0.1912,  0.0311, -0.0235, -0.1724, -0.0274, -0.0295, -0.1031,\n",
      "         0.0047,  0.0828, -0.1521,  0.0183, -0.2418, -0.0831, -0.0491, -0.0688,\n",
      "        -0.2560,  0.1381, -0.0165,  0.2092, -0.0028, -0.0265, -0.0225,  0.0286,\n",
      "        -0.1065, -0.3698,  0.2862, -0.1036,  0.3080, -0.0894,  0.2772,  0.1136,\n",
      "        -0.3157,  0.0423,  0.0567,  0.2369, -0.0727,  0.0465, -0.0536,  0.1309,\n",
      "         0.0282, -0.1371,  0.1464, -0.0717, -0.3237, -0.1583, -0.0424, -0.1278,\n",
      "        -0.1703,  0.0413,  0.0891,  0.0770, -0.0730,  0.0683, -0.0391,  0.0476],\n",
      "       requires_grad=True)}\n",
      "Done loading BasicBlock weights!\n"
     ]
    }
   ],
   "source": [
    "net_tf.load_weigths_pytorch(\"resnet18-5c106cde.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_resnet18_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1225 (Conv2D)         multiple                  9408      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1224 (Ba multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_428 (Sequential)  multiple                  148480    \n",
      "_________________________________________________________________\n",
      "sequential_429 (Sequential)  multiple                  526848    \n",
      "_________________________________________________________________\n",
      "sequential_431 (Sequential)  multiple                  2102272   \n",
      "_________________________________________________________________\n",
      "sequential_433 (Sequential)  multiple                  8398848   \n",
      "=================================================================\n",
      "Total params: 11,186,112\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 28, 28])\n",
      "torch.Size([16, 256, 14, 14])\n",
      "torch.Size([16, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "net = Resnet18()\n",
    "x = torch.randn(16, 3, 224, 224)\n",
    "out = net(x)\n",
    "print(out[0].size())\n",
    "print(out[1].size())\n",
    "print(out[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet18(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"resnet18-5c106cde.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.running_mean',\n",
       " 'bn1.running_var',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.running_mean',\n",
       " 'layer1.0.bn1.running_var',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.running_mean',\n",
       " 'layer1.0.bn2.running_var',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.running_mean',\n",
       " 'layer1.1.bn1.running_var',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.running_mean',\n",
       " 'layer1.1.bn2.running_var',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.running_mean',\n",
       " 'layer2.0.bn1.running_var',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.running_mean',\n",
       " 'layer2.0.bn2.running_var',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.running_mean',\n",
       " 'layer2.0.downsample.1.running_var',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.running_mean',\n",
       " 'layer2.1.bn1.running_var',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.running_mean',\n",
       " 'layer2.1.bn2.running_var',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.running_mean',\n",
       " 'layer3.0.bn1.running_var',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.running_mean',\n",
       " 'layer3.0.bn2.running_var',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.running_mean',\n",
       " 'layer3.0.downsample.1.running_var',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.running_mean',\n",
       " 'layer3.1.bn1.running_var',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.running_mean',\n",
       " 'layer3.1.bn2.running_var',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.running_mean',\n",
       " 'layer4.0.bn1.running_var',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.running_mean',\n",
       " 'layer4.0.bn2.running_var',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.running_mean',\n",
       " 'layer4.0.downsample.1.running_var',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.running_mean',\n",
       " 'layer4.1.bn1.running_var',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.running_mean',\n",
       " 'layer4.1.bn2.running_var',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'bn1.running_mean',\n",
       " 'bn1.running_var',\n",
       " 'bn1.num_batches_tracked',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.bn1.running_mean',\n",
       " 'layer1.0.bn1.running_var',\n",
       " 'layer1.0.bn1.num_batches_tracked',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.0.bn2.running_mean',\n",
       " 'layer1.0.bn2.running_var',\n",
       " 'layer1.0.bn2.num_batches_tracked',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.bn1.running_mean',\n",
       " 'layer1.1.bn1.running_var',\n",
       " 'layer1.1.bn1.num_batches_tracked',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer1.1.bn2.running_mean',\n",
       " 'layer1.1.bn2.running_var',\n",
       " 'layer1.1.bn2.num_batches_tracked',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.bn1.running_mean',\n",
       " 'layer2.0.bn1.running_var',\n",
       " 'layer2.0.bn1.num_batches_tracked',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.bn2.running_mean',\n",
       " 'layer2.0.bn2.running_var',\n",
       " 'layer2.0.bn2.num_batches_tracked',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.0.downsample.1.running_mean',\n",
       " 'layer2.0.downsample.1.running_var',\n",
       " 'layer2.0.downsample.1.num_batches_tracked',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.bn1.running_mean',\n",
       " 'layer2.1.bn1.running_var',\n",
       " 'layer2.1.bn1.num_batches_tracked',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer2.1.bn2.running_mean',\n",
       " 'layer2.1.bn2.running_var',\n",
       " 'layer2.1.bn2.num_batches_tracked',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.bn1.running_mean',\n",
       " 'layer3.0.bn1.running_var',\n",
       " 'layer3.0.bn1.num_batches_tracked',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.bn2.running_mean',\n",
       " 'layer3.0.bn2.running_var',\n",
       " 'layer3.0.bn2.num_batches_tracked',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.0.downsample.1.running_mean',\n",
       " 'layer3.0.downsample.1.running_var',\n",
       " 'layer3.0.downsample.1.num_batches_tracked',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.bn1.running_mean',\n",
       " 'layer3.1.bn1.running_var',\n",
       " 'layer3.1.bn1.num_batches_tracked',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer3.1.bn2.running_mean',\n",
       " 'layer3.1.bn2.running_var',\n",
       " 'layer3.1.bn2.num_batches_tracked',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.bn1.running_mean',\n",
       " 'layer4.0.bn1.running_var',\n",
       " 'layer4.0.bn1.num_batches_tracked',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.bn2.running_mean',\n",
       " 'layer4.0.bn2.running_var',\n",
       " 'layer4.0.bn2.num_batches_tracked',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.0.downsample.1.running_mean',\n",
       " 'layer4.0.downsample.1.running_var',\n",
       " 'layer4.0.downsample.1.num_batches_tracked',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.bn1.running_mean',\n",
       " 'layer4.1.bn1.running_var',\n",
       " 'layer4.1.bn1.num_batches_tracked',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'layer4.1.bn2.running_mean',\n",
       " 'layer4.1.bn2.running_var',\n",
       " 'layer4.1.bn2.num_batches_tracked']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: conv1.weight\t\t\t\tshape: (64, 3, 7, 7)\n",
      "layer: bn1.running_mean\t\t\t\tshape: (64,)\n",
      "layer: bn1.running_var\t\t\t\tshape: (64,)\n",
      "layer: bn1.weight\t\t\t\tshape: (64,)\n",
      "layer: bn1.bias\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.conv1.weight\t\t\t\tshape: (64, 64, 3, 3)\n",
      "layer: layer1.0.bn1.running_mean\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.bn1.running_var\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.bn1.weight\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.bn1.bias\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.conv2.weight\t\t\t\tshape: (64, 64, 3, 3)\n",
      "layer: layer1.0.bn2.running_mean\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.bn2.running_var\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.bn2.weight\t\t\t\tshape: (64,)\n",
      "layer: layer1.0.bn2.bias\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.conv1.weight\t\t\t\tshape: (64, 64, 3, 3)\n",
      "layer: layer1.1.bn1.running_mean\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.bn1.running_var\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.bn1.weight\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.bn1.bias\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.conv2.weight\t\t\t\tshape: (64, 64, 3, 3)\n",
      "layer: layer1.1.bn2.running_mean\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.bn2.running_var\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.bn2.weight\t\t\t\tshape: (64,)\n",
      "layer: layer1.1.bn2.bias\t\t\t\tshape: (64,)\n",
      "layer: layer2.0.conv1.weight\t\t\t\tshape: (128, 64, 3, 3)\n",
      "layer: layer2.0.bn1.running_mean\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.bn1.running_var\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.bn1.weight\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.bn1.bias\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.conv2.weight\t\t\t\tshape: (128, 128, 3, 3)\n",
      "layer: layer2.0.bn2.running_mean\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.bn2.running_var\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.bn2.weight\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.bn2.bias\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.downsample.0.weight\t\t\t\tshape: (128, 64, 1, 1)\n",
      "layer: layer2.0.downsample.1.running_mean\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.downsample.1.running_var\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.downsample.1.weight\t\t\t\tshape: (128,)\n",
      "layer: layer2.0.downsample.1.bias\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.conv1.weight\t\t\t\tshape: (128, 128, 3, 3)\n",
      "layer: layer2.1.bn1.running_mean\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.bn1.running_var\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.bn1.weight\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.bn1.bias\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.conv2.weight\t\t\t\tshape: (128, 128, 3, 3)\n",
      "layer: layer2.1.bn2.running_mean\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.bn2.running_var\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.bn2.weight\t\t\t\tshape: (128,)\n",
      "layer: layer2.1.bn2.bias\t\t\t\tshape: (128,)\n",
      "layer: layer3.0.conv1.weight\t\t\t\tshape: (256, 128, 3, 3)\n",
      "layer: layer3.0.bn1.running_mean\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.bn1.running_var\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.bn1.weight\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.bn1.bias\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.conv2.weight\t\t\t\tshape: (256, 256, 3, 3)\n",
      "layer: layer3.0.bn2.running_mean\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.bn2.running_var\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.bn2.weight\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.bn2.bias\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.downsample.0.weight\t\t\t\tshape: (256, 128, 1, 1)\n",
      "layer: layer3.0.downsample.1.running_mean\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.downsample.1.running_var\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.downsample.1.weight\t\t\t\tshape: (256,)\n",
      "layer: layer3.0.downsample.1.bias\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.conv1.weight\t\t\t\tshape: (256, 256, 3, 3)\n",
      "layer: layer3.1.bn1.running_mean\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.bn1.running_var\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.bn1.weight\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.bn1.bias\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.conv2.weight\t\t\t\tshape: (256, 256, 3, 3)\n",
      "layer: layer3.1.bn2.running_mean\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.bn2.running_var\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.bn2.weight\t\t\t\tshape: (256,)\n",
      "layer: layer3.1.bn2.bias\t\t\t\tshape: (256,)\n",
      "layer: layer4.0.conv1.weight\t\t\t\tshape: (512, 256, 3, 3)\n",
      "layer: layer4.0.bn1.running_mean\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.bn1.running_var\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.bn1.weight\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.bn1.bias\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.conv2.weight\t\t\t\tshape: (512, 512, 3, 3)\n",
      "layer: layer4.0.bn2.running_mean\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.bn2.running_var\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.bn2.weight\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.bn2.bias\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.downsample.0.weight\t\t\t\tshape: (512, 256, 1, 1)\n",
      "layer: layer4.0.downsample.1.running_mean\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.downsample.1.running_var\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.downsample.1.weight\t\t\t\tshape: (512,)\n",
      "layer: layer4.0.downsample.1.bias\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.conv1.weight\t\t\t\tshape: (512, 512, 3, 3)\n",
      "layer: layer4.1.bn1.running_mean\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.bn1.running_var\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.bn1.weight\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.bn1.bias\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.conv2.weight\t\t\t\tshape: (512, 512, 3, 3)\n",
      "layer: layer4.1.bn2.running_mean\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.bn2.running_var\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.bn2.weight\t\t\t\tshape: (512,)\n",
      "layer: layer4.1.bn2.bias\t\t\t\tshape: (512,)\n",
      "layer: fc.weight\t\t\t\tshape: (1000, 512)\n",
      "layer: fc.bias\t\t\t\tshape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in state_dict.items():\n",
    "    v = v.detach().numpy()\n",
    "    \n",
    "    print(f\"layer: {k}\\t\\t\\t\\tshape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(keras.layers.Layer)\n",
    "    def __init__(self, in_chan, out_chan, ks=3, stride=1, padding=1, *args, **kwargs):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "        \n",
    "        self.conv = keras.layers.Conv2D(\n",
    "                out_chan,\n",
    "                kernel_size = ks,\n",
    "                strides = stride,\n",
    "                padding = padding,\n",
    "                use_bias = False)\n",
    "        \n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = tf.nn.relu(self.bn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiSeNetOutput(keras.layers.Layer):\n",
    "    def __init__(self, in_chan, mid_chan, n_classes, *args, **kwargs):\n",
    "        super(BiSeNetOutput, self).__init__()\n",
    "        \n",
    "        self.conv = ConvBNReLU(in_chan, \n",
    "                               mid_chan, \n",
    "                               ks=3, \n",
    "                               stride=1, \n",
    "                               padding=\"same\")\n",
    "        self.conv_out = keras.layers.Conv2D(\n",
    "#                                 mid_chan, \n",
    "                                  n_classes, \n",
    "                                  kernel_size=1, \n",
    "                                  use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionRefinementModule(keras.layers.Layer):\n",
    "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
    "        super(AttentionRefinementModule, self).__init__()\n",
    "        \n",
    "        self.conv = ConvBNReLU(in_chan, \n",
    "                               out_chan, \n",
    "                               ks=3, \n",
    "                               stride=1, \n",
    "                               padding=\"same\")\n",
    "        \n",
    "        self.conv_atten = keras.layers.Conv2D(\n",
    "#                                     out_chan, \n",
    "                                    out_chan, \n",
    "                                    kernel_size=1, \n",
    "                                    use_bias=False)\n",
    "        \n",
    "        self.bn_atten = keras.layers.BatchNormalization()\n",
    "        self.sigmoid_atten = keras.layers.Activation(\"sigmoid\")\n",
    "        self.avg_pool2d = keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv(x)\n",
    "#         atten = self.avg_pool2d(feat, feat.size()[2:])\n",
    "        atten = self.avg_pool2d(feat)\n",
    "        atten = self.conv_atten(atten)\n",
    "        atten = self.bn_atten(atten)\n",
    "        atten = self.sigmoid_atten(atten)\n",
    "        out = tf.math.muliply(feat, atten)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextPath(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ContextPath, self).__init__()\n",
    "        \n",
    "        self.resnet = Resnet18()\n",
    "        self.arm16 = AttentionRefinementModule(256, 128)\n",
    "        self.arm32 = AttentionRefinementModule(512, 128)\n",
    "        self.conv_head32 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
    "        self.conv_head16 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
    "        self.conv_avg = ConvBNReLU(512, 128, ks=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H0, W0 = x.size()[2:]\n",
    "        \n",
    "        feat8, feat16, feat32 = self.resnet(x)\n",
    "        H8, W8 = feat8.size()[2:]\n",
    "        H16, W16 = feat16.size()[2:]\n",
    "        H32, W32 = feat32.size()[2:]\n",
    "\n",
    "        avg = F.avg_pool2d(feat32, feat32.size()[2:])\n",
    "        avg = self.conv_avg(avg)\n",
    "        avg_up = F.interpolate(avg, (H32, W32), mode='nearest')\n",
    "\n",
    "        feat32_arm = self.arm32(feat32)\n",
    "        feat32_sum = feat32_arm + avg_up\n",
    "        feat32_up = F.interpolate(feat32_sum, (H16, W16), mode='nearest')\n",
    "        feat32_up = self.conv_head32(feat32_up)\n",
    "\n",
    "        feat16_arm = self.arm16(feat16)\n",
    "        feat16_sum = feat16_arm + feat32_up\n",
    "        feat16_up = F.interpolate(feat16_sum, (H8, W8), mode='nearest')\n",
    "        feat16_up = self.conv_head16(feat16_up)\n",
    "\n",
    "        return feat8, feat16_up, feat32_up  # x8, x8, x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureFusionModule(keras.layers.Layer):\n",
    "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
    "        super(FeatureFusionModule, self).__init__()\n",
    "        \n",
    "        self.convblk = ConvBNReLU(\n",
    "            in_chan,\n",
    "            out_chan,\n",
    "            ks=1,\n",
    "            stride=1,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        \n",
    "        self.conv1 = keras.layers.Conv2d(\n",
    "#             out_chan,\n",
    "            out_chan//4,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv2D(\n",
    "#             out_chan//4,\n",
    "            out_chan,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False\n",
    "        )\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        fsp, fcp = inputs\n",
    "        fcat = K.concatenate([fsp, fcp], axis=3)\n",
    "        \n",
    "        feat = self.convblk(fcat)\n",
    "        \n",
    "        atten = K.pool2d(feat, feat.shape[1:2+1], pool_mode=\"avg\")\n",
    "        atten = self.conv1(atten)\n",
    "        atten = K.relu(atten)\n",
    "        atten = self.conv2(atten)\n",
    "        atten = K.sigmoid(atten)\n",
    "        feat_atten = tf.math.multiply(feat, atten)\n",
    "        feat_out = feat_atten + feat\n",
    "        return feat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tfBiSeNet(keras.models.Model):\n",
    "    def __init__(self, n_classes, *args, **kwargs):\n",
    "        super(tfBiSeNet, self).__init__()\n",
    "        \n",
    "        self.cp = ContextPath()\n",
    "        ## here self.sp is deleted\n",
    "        \n",
    "        self.ffm = FeatureFusionModule(256, 256)\n",
    "        \n",
    "        self.conv_out = BiSeNetOutput(256, 256, n_classes)\n",
    "        self.conv_out16 = BiSeNetOutput(128, 64, n_classes)\n",
    "        self.conv_out32 = BiSeNetOutput(128, 64, n_classes)\n",
    "        \n",
    "        self.image_data_format = K.image_data_format()\n",
    "\n",
    "    def call(self, x):\n",
    "#         H, W = x.size()[2:]\n",
    "        H, W = x.shape[1:2+1]\n",
    "        print(f\"H: {H}, W: {W}\")\n",
    "    \n",
    "        feat_res8, feat_cp8, feat_cp16 = self.cp(x)  # here return res3b1 feature\n",
    "        \n",
    "        feat_sp = feat_res8  # use res3b1 feature to replace spatial path feature\n",
    "        feat_fuse = self.ffm(feat_sp, feat_cp8)\n",
    "\n",
    "        feat_out = self.conv_out(feat_fuse)\n",
    "        feat_out16 = self.conv_out16(feat_cp8)\n",
    "        feat_out32 = self.conv_out32(feat_cp16)\n",
    "\n",
    "        feat_out = K.resize_images(feat_out, \n",
    "                                   H, W, \n",
    "                                   data_format=self.image_data_format, \n",
    "                                   interpolation='bilinear')\n",
    "        feat_out16 = K.resize_images(feat_out16, \n",
    "                                     H, W, \n",
    "                                     data_format=self.image_data_format, \n",
    "                                     interpolation='bilinear')\n",
    "        feat_out32 = K.resize_images(feat_out32, \n",
    "                                     H, W, \n",
    "                                     data_format=self.image_data_format, \n",
    "                                     interpolation='bilinear')\n",
    "        \n",
    "        return feat_out, feat_out16, feat_out32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ContextPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f7f3950ac60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfBiSeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-3c070ee3d202>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_classes, *args, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfBiSeNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContextPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m## here self.sp is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ContextPath' is not defined"
     ]
    }
   ],
   "source": [
    "model_tf = tfBiSeNet(n_classes=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
